,Unnamed: 0.1,Unnamed: 0,Title,Publication Title,Volume,Issue,DOI,Authors,Publication Year,URL,Type,Abstract,Keywords,ISBN,ISSN,Date,Date Added,Date Modified,Pages,Series,Publisher,Key,Eligibility_Abstract_Score,Eligibility_Keywords_Score,Eligibility_Title_Score,Eligibility_Score
0,0,0,Implementing Artificial Intelligence Ethics In&nbsp;Trustworthy System Development - Making AI Ethics A&nbsp;Business Case,"Product-Focused Software Process Improvement: 23rd International Conference, PROFES 2022, Jyväskylä, Finland, November 21–23, 2022, Proceedings",,,10.1007/978-3-031-21388-5_52,"Agbese, Mamia",2022.0,https://doi.org/10.1007/978-3-031-21388-5_52,conferencePaper,"Software businesses struggle to implement AI ethics or ethical requirements in their development and engineering of AI. Current tools mainly focus on the technical level, with scarce resources identified for the different groups across software business organizations. This study focuses on developing a proposed solution, the ethical requirement stack, as a toolkit software businesses can leverage to implement ethical requirements. The tool aims to improve the understanding and visibility of AI ethics by serving as a go-to in interpreting AI ethics guidelines, thereby reducing the gap in transitioning AI ethics from principles to practice.",AI Ethics; AI ethics principles; Artificial Intelligence; Ethical requirement stack; Ethical requirements; Software businesses,978-3-031-21387-8,,2022,2023-11-06 01:29:48,2023-11-06 01:29:48,656–661,,Springer-Verlag,RCRK9GYA,0.2340425531914893,0.8571428571428571,0.3846153846153846,0.3424100294013188
1,1,1,An AI Ethics Course Highlighting Explicit Ethical Agents,"Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3461702.3462552,"Green, Nancy",2021.0,https://doi.org/10.1145/3461702.3462552,conferencePaper,"This is an experience report describing a pilot AI Ethics course for undergraduate computer science majors. In addition to teaching students about different ethical approaches and using them to analyze ethical issues, the course covered how ethics has been incorporated into the implementation of explicit ethical agents, and required students to implement an explicit ethical agent for a simple application. This report describes the course objectives and design, the topics covered, and a qualitative evaluation with suggestions for future offerings of the courses.",AI ethics; ethics education; explicit ethical agents,978-1-4503-8473-5,,2021,2023-11-06 01:29:48,2023-11-06 01:29:48,519–524,AIES '21,Association for Computing Machinery,KXWK8WI4,0.2048192771084337,1.1428571428571428,0.75,0.3223127430356346
3,4,4,Ethical Requirements Stack: A Framework for Implementing Ethical Requirements of AI in Software Engineering Practices,Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering,,,10.1145/3593434.3593489,"Agbese, Mamia; Mohanani, Rahul; Khan, Arif Ali; Abrahamsson, Pekka",2023.0,https://doi.org/10.1145/3593434.3593489,conferencePaper,"""The ethical requirements stack uses an Agile portfolio manage- ment framework based on agile scrum practices of themes, epics, features, and stories [3, 5] for a practical and hands-on approach to implementing ethical requirements of artificial intelligence (AI) into software engineering (SE) management practices. The frame- work is conceptualized as spread across actor groups of higher-level management (strategy level activities), middle-level management (product management activities), operational or development levels, and individual or team levels. The executive or strategy layer corresponds to the themes layer in the Agile portfolio management framework. This layer creates strategic, ethical requirements for the business. Ethical require- ments are determined at this stage using appropriate ethical frame- works or tools based on AI ethics guidelines and principles to create a central or strategic ethical requirements theme. """,AI ethics; AI ethics principles; Ethical requirements; AI; Agile portfolio management; Ethical requirements stack,9798400700446,,2023,2023-11-06 01:30:00,2023-11-06 01:30:00,326–328,EASE '23,Association for Computing Machinery,N49EFHB9,0.1679389312977099,0.9285714285714286,0.4666666666666667,0.2708347757488573
4,5,5,Implementing AI Ethics: Making Sense of the Ethical Requirements,Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering,,,10.1145/3593434.3593453,"Agbese, Mamia; Mohanani, Rahul; Khan, Arif; Abrahamsson, Pekka",2023.0,https://doi.org/10.1145/3593434.3593453,conferencePaper,"Society’s increasing dependence on Artificial Intelligence (AI) and AI-enabled systems require a more practical approach from software engineering (SE) executives in middle and higher-level management to improve their involvement in implementing AI ethics by making ethical requirements part of their management practices. However, research indicates that most work on implementing ethical requirements in SE management primarily focuses on technical development, with scarce findings for middle and higher-level management. We investigate this by interviewing ten Finnish SE executives in middle and higher-level management to examine how they consider and implement ethical requirements. We use ethical requirements from the European Union (EU) Trustworthy Ethics guidelines for Trustworthy AI as our reference for ethical requirements and an Agile portfolio management framework to analyze implementation. Our findings reveal a general consideration of privacy and data governance ethical requirements as legal requirements with no other consideration for ethical requirements identified. The findings also show practicable consideration of ethical requirements as technical robustness and safety for implementation as risk requirements and societal and environmental well-being for implementation as sustainability requirements. We examine a practical approach to implementing ethical requirements using the ethical risk requirements stack employing the Agile portfolio management framework.",Agile portfolio management; AI; AI ethics; AI ethics principles; Ethical requirements; Ethical requirements stack,9798400700446,,2023,2023-11-06 01:29:48,2023-11-06 01:29:48,62–71,EASE '23,Association for Computing Machinery,EVKFC8AL,0.2,0.9285714285714286,0.6666666666666666,0.2671024151287309
5,6,6,AI Ethics - Critical Reflections on Embedding Ethical Frameworks in AI Technology,"Culture and Computing. Design Thinking and Cultural Computing: 9th International Conference, C&amp;C 2021, Held as Part of the 23rd HCI International Conference, HCII 2021, Virtual Event, July 24–29, 2021, Proceedings, Part II",,,10.1007/978-3-030-77431-8_20,"Salo-Pöntinen, Henrikki",2021.0,https://doi.org/10.1007/978-3-030-77431-8_20,conferencePaper,"Embedding ethical frameworks in artificial intelligence (AI) technologies has been a popular topic for academic research for the past decade [1–7]. The approaches of the studies differ in how AI technology, ethics, role of technical artefacts and socio-technical aspects of AI are perceived. In addition, most studies define insufficiently what the connection between the process of embedding ethical frameworks to AI technology and the larger framework of AI ethics is. These deficiencies have caused that the concept of AI ethics and the construct of embedding ethical parameters into AI are used in an ambiguous, rather than in a complementary manner.One reason for the ambiguity within this field of research is due to a lack of a comprehensive conceptual framework for AI ethics in general. I intend to fill this void by grounding AI ethics as a subfield of philosophy of technology and applied ethics and presenting its main issues of study by examining recognized spheres of activities through the method of levels of abstraction [8]. I put forward an initial hierarchical conceptual framework for AI ethics as an outcome. After this, I discuss the connection between the process of embedding ethical frameworks in AI and the larger AI ethics framework, leading to presenting basic requirements for the sphere of activity hereafter known as embedded ethics.",AI ethics; Applied ethics; Embedded ethics; Human-technology interaction,978-3-030-77430-1,,2021,2023-11-06 01:29:48,2023-11-06 01:29:48,311–329,,Springer-Verlag,T2JKNGZ8,0.1953488372093023,0.875,0.5833333333333334,0.2483228832916864
7,8,8,A Principlist Framework for Cybersecurity Ethics,Comput. Secur.,109.0,C,10.1016/j.cose.2021.102382,"Formosa, Paul; Wilson, Michael; Richards, Deborah",2021.0,https://doi.org/10.1016/j.cose.2021.102382,journalArticle,"The ethical issues raised by cybersecurity practices and technologies are of critical importance. However, there is disagreement about what is the best ethical framework for understanding those issues. In this paper we seek to address this shortcoming through the introduction of a principlist ethical framework for cybersecurity that builds on existing work in adjacent fields of applied ethics, bioethics, and AI ethics. By redeploying the AI4People framework, we develop a domain-relevant specification of five ethical principles in cybersecurity: beneficence, non-maleficence, autonomy, justice, and explicability. We then illustrate the advantages of this principlist framework by examining the ethical issues raised by four common cybersecurity contexts: penetration testing, distributed denial of service attacks (DDoS), ransomware, and system administration. These case analyses demonstrate the utility of this principlist framework as a basis for understanding cybersecurity ethics and for cultivating the ethical expertise and ethical sensitivity of cybersecurity professionals and other stakeholders.",AI ethics; Privacy; Cybersecurity ethics; DDoS attacks; Penetration testing; Principlism; Ransomware,,0167-4048,2021-10,2023-11-06 01:29:59,2023-11-06 01:29:59,,,,VXFLFHHR,0.2027027027027027,0.5454545454545454,0.3333333333333333,0.2349071940017134
8,10,10,"Operationalising AI Ethics: Barriers, Enablers and next Steps",AI Soc.,38.0,1,10.1007/s00146-021-01308-8,"Morley, Jessica; Kinsey, Libby; Elhalal, Anat; Garcia, Francesca; Ziosi, Marta; Floridi, Luciano",2021.0,https://doi.org/10.1007/s00146-021-01308-8,journalArticle,"By mid-2019 there were more than 80 AI ethics guides available in the public domain. Despite this, 2020 saw numerous news stories break related to ethically questionable uses of AI. In part, this is because AI ethics theory remains highly abstract, and of limited practical applicability to those actually responsible for designing algorithms and AI systems. Our previous research sought to start closing this gap between the ‘what’ and the ‘how’ of AI ethics through the creation of a searchable typology of tools and methods designed to translate between the five most common AI ethics principles and implementable design practices. Whilst a useful starting point, that research rested on the assumption that all AI practitioners are aware of the ethical implications of AI, understand their importance, and are actively seeking to respond to them. In reality, it is unclear whether this is the case. It is this limitation that we seek to overcome here by conducting a mixed-methods qualitative analysis to answer the following four questions: what do AI practitioners understand about the need to translate ethical principles into practice? What motivates AI practitioners to embed ethical principles into design practices? What barriers do AI practitioners face when attempting to translate ethical principles into practice? And finally, what assistance do AI practitioners want and need when translating ethical principles into practice?",AI ethics; Applied ethics; Business ethics; Ethical practices; Ethical principles,,0951-5666,2021-11,2023-11-06 01:29:48,2023-11-06 01:29:48,411–423,,,XQQGTU4X,0.1583710407239819,1.3,0.375,0.2250921974267562
9,11,11,User Perspectives on Ethical Challenges in Human-AI Co-Creativity: A Design Fiction Study,Proceedings of the 15th Conference on Creativity and Cognition,,,10.1145/3591196.3593364,"Rezwana, Jeba; Maher, Mary Lou",2023.0,https://doi.org/10.1145/3591196.3593364,conferencePaper,"In a human-AI co-creation, AI not only categorizes, evaluates and interprets data but also generates new content and interacts with humans. As co-creative AI is a form of intelligent technology that directly involves humans, it is critical to anticipate and address ethical issues during all design stages. The open-ended nature of human-AI interactions in co-creation poses many challenges for designing ethical co-creative AI systems. Researchers have been exploring ethical issues associated with autonomous AI in recent years, but ethics in human-AI co-creativity is a relatively new research area. In order to design human-centered ethical AI, it is important to understand the perspectives, expectations, and ethical concerns of potential users. In this paper, we present a study with 18 participants to explore several ethical dilemmas and challenges in human-AI co-creation from the perspective of potential users using a design fiction (DF) methodology. DF is a speculative research method that depicts a new concept or technology through stories as an intangible prototype. We present the findings from the study as potential users’ perspectives, stances, and expectations around ethical challenges in human-AI co-creativity as a basis for designing human-centered ethical AI partners for human-AI co-creation.",AI Ethics; Co-creativity; Design Fiction; Ethical AI; Ethical Issues; Human-AI Co-Creation,9798400701801,,2023,2023-11-06 01:30:01,2023-11-06 01:30:01,62–74,C&amp;C '23,Association for Computing Machinery,9N22T8PQ,0.171875,0.9090909090909092,0.25,0.2207759718600279
10,12,12,Artificial Intelligence Ethics Guidelines for K-12 Education: A Review of the Global Landscape,"Artificial Intelligence in Education: 22nd International Conference, AIED 2021, Utrecht, The Netherlands, June 14–18, 2021, Proceedings, Part II",,,10.1007/978-3-030-78270-2_4,"Adams, Cathy; Pente, Patti; Lemermeyer, Gillian; Rockwell, Geoffrey",2021.0,https://doi.org/10.1007/978-3-030-78270-2_4,conferencePaper,"To scope the global landscape of ethical issues involving the use of AI in K-12 education, we identified relevant ethics guidance documents, and then compared and contrasted concerns raised and principles applied. We found that while AIEdK-12 ethics guidelines employed many principles common to non-AIEd policy statements (e.g., transparency), new ethical principles were being engaged including pedagogical appropriateness and children’s rights.",AI literacy; AI and ethics; AI ethics guidelines; Artificial intelligence in education; Children’s rights; K-12 education; Teacher well-being,978-3-030-78269-6,,2021,2023-11-06 01:30:04,2023-11-06 01:30:04,24–28,,Springer-Verlag,EJS6LDIG,0.180327868852459,0.3888888888888889,0.1538461538461538,0.219796816967626
11,13,13,The Cost of Ethical AI Development for AI Startups,"Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3514094.3534195,"Bessen, James; Impink, Stephen Michael; Seamans, Robert",2022.0,https://doi.org/10.1145/3514094.3534195,conferencePaper,"Artificial Intelligence startups use training data as direct inputs in product development. These firms must balance numerous tradeoffs between ethical issues and data access without substantive guidance from regulators or existing judicial precedence. We survey these startups to determine what actions they have taken to address these ethical issues and the consequences of those actions. We find that 58% of these startups have established a set of AI principles. Startups with data-sharing relationships with high-technology firms or that have prior experience with privacy regulations are more likely to establish ethical AI principles and are more likely to take costly steps, like dropping training data or turning down business, to adhere to their ethical AI policies. Moreover, startups with ethical AI policies are more likely to invest in unconscious bias training, hire ethnic minorities and female programmers, seek expert advice, and search for more diverse training data. Potential costs associated with data-sharing relationships and the adherence to ethical policies may create tradeoffs between increased AI product competition and more ethical AI production.",ethics; AI; data; scale barriers; startups,978-1-4503-9247-1,,2022,2023-11-06 01:29:57,2023-11-06 01:29:57,92–106,AIES '22,Association for Computing Machinery,H9LSTATR,0.1871345029239766,0.6666666666666666,0.5555555555555556,0.2175217397315195
13,15,15,From AI for People to AI for the World and the Universe,AI Soc.,38.0,2,10.1007/s00146-022-01402-5,"Baum, Seth D.; Owe, Andrea",2022.0,https://doi.org/10.1007/s00146-022-01402-5,journalArticle,"Recent work in AI ethics often calls for AI to advance human values and interests. The concept of “AI for people” is one notable example. Though commendable in some respects, this work falls short by excluding the moral significance of nonhumans. This paper calls for a shift in AI ethics to more inclusive paradigms such as “AI for the world” and “AI for the universe”. The paper outlines the case for more inclusive paradigms and presents implications for moral philosophy and computer science work on AI ethics.",AI ethics; AI for people; Environmental ethics; Nonhumans,,0951-5666,2022-02,2023-11-06 01:29:50,2023-11-06 01:29:50,679–680,,,LQS5HU5H,0.1494252873563218,0.75,0.1666666666666666,0.2056250229517829
14,16,16,The State of Ethical AI in Practice: A Multiple Case Study of Estonian Public Service Organizations,Int. J. Technoethics,14.0,1,10.4018/IJT.322017,"Hinton, Charlene",2023.0,https://doi.org/10.4018/IJT.322017,journalArticle,"Despite the prolific introduction of ethical frameworks, empirical research on AI ethics in the public sector is limited. This empirical research investigates how the ethics of AI is translated into practice and the challenges of its implementation by public service organizations. Using the Value Sensitive Design as a framework of inquiry, semi-structured interviews are conducted with eight public service organizations across the Estonian government that have piloted or developed an AI solution for delivering a public service. Results show that the practical application of AI ethical principles is indirectly considered and demonstrated in different ways in the design and development of the AI. However, translation of these principles varies according to the maturity of the AI and the public servant's level of awareness, knowledge, and competences in AI. Data-related challenges persist as public service organizations work on fine-tuning their AI applications.",Ethics; Artificial Intelligence; AI Ethical Principles; Estonia; Ethical AI Design and Development; Practical Application of AI Ethics; Public Sector; Value Sensitive Design,,1947-3451,2023-04,2023-11-06 01:29:59,2023-11-06 01:29:59,1–15,,,3Z9FZKRF,0.1276595744680851,0.5909090909090909,0.25,0.2018186327252825
15,17,17,Modeling and Guiding the Creation of Ethical Human-AI Teams,"Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3461702.3462573,"Flathmann, Christopher; Schelble, Beau G.; Zhang, Rui; McNeese, Nathan J.",2021.0,https://doi.org/10.1145/3461702.3462573,conferencePaper,"With artificial intelligence continuing to advance, so too do the ethical concerns that can potentially negatively impact humans and the greater society. When these systems begin to interact with humans, these concerns become much more complex and much more important. The field of human-AI teaming provides a relevant example of how AI ethics can have significant and continued effects on humans. This paper reviews research in ethical artificial intelligence, as well as ethical teamwork through the lens of the rapidly advancing field of human-AI teaming, resulting in a model demonstrating the requirements and outcomes of building ethical human-AI teams. The model is created to guide the prioritization of ethics in human-AI teaming by outlining the ethical teaming process, outcomes of ethical teams, and external requirements necessary to ensure ethical human-AI teams. A final discussion is presented on how the developed model will influence the implementation of AI teammates, as well as the development of policy and regulation surrounding the domain in the coming years.",AI ethics; artificial intelligence; human-AI ethics; human-AI teamwork,978-1-4503-8473-5,,2021,2023-11-06 01:29:49,2023-11-06 01:29:49,469–479,AIES '21,Association for Computing Machinery,PMTFXUSL,0.1646341463414634,0.625,0.3333333333333333,0.1994351874211811
16,18,18,Ethics of AI: A Systematic Literature Review of Principles and Challenges,Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering,,,10.1145/3530019.3531329,"Khan, Arif Ali; Badshah, Sher; Liang, Peng; Waseem, Muhammad; Khan, Bilal; Ahmad, Aakash; Fahmideh, Mahdi; Niazi, Mahmood; Akbar, Muhammad Azeem",2022.0,https://doi.org/10.1145/3530019.3531329,conferencePaper,"Ethics in AI becomes a global topic of interest for both policymakers and academic researchers. In the last few years, various research organizations, lawyers, think tankers, and regulatory bodies get involved in developing AI ethics guidelines and principles. However, there is still debate about the implications of these principles. We conducted a systematic literature review (SLR) study to investigate the agreement on the significance of AI principles and identify the challenging factors that could negatively impact the adoption of AI ethics principles. The results reveal that the global convergence set consists of 22 ethical principles and 15 challenges. Transparency, privacy, accountability and fairness are identified as the most common AI ethics principles. Similarly, lack of ethical knowledge and vague principles are reported as the significant challenges for considering ethics in AI. The findings of this study are the preliminary inputs for proposing a maturity model that assesses the ethical capabilities of AI systems and provides best practices for further improvements.",AI Ethics; Principles; Challenges; Machine Ethics; Systematic Literature Review,978-1-4503-9613-4,,2022,2023-11-06 01:29:55,2023-11-06 01:29:55,383–392,EASE '22,Association for Computing Machinery,JD9H6H5T,0.16875,0.5555555555555556,0.2727272727272727,0.1993418041683879
17,19,19,"Integrating AI Ethics in Wildlife Conservation AI Systems in South Africa: A Review, Challenges, and Future Research Agenda",AI Soc.,38.0,1,10.1007/s00146-021-01285-y,"Nandutu, Irene; Atemkeng, Marcellin; Okouma, Patrice",2021.0,https://doi.org/10.1007/s00146-021-01285-y,journalArticle,"With the increased use of Artificial Intelligence (AI) in wildlife conservation, issues around whether AI-based monitoring tools in wildlife conservation comply with standards regarding AI Ethics are on the rise. This review aims to summarise current debates and identify gaps as well as suggest future research by investigating (1) current AI Ethics and AI Ethics issues in wildlife conservation, (2) Initiatives Stakeholders in AI for wildlife conservation should consider integrating AI Ethics in wildlife conservation. We find that the existing literature weakly focuses on AI Ethics and AI Ethics in wildlife conservation while at the same time ignores AI Ethics integration in AI systems for wildlife conservation. This paper formulates an ethically aligned AI system framework and discusses pre-eminent on-demand AI systems in wildlife conservation. The proposed framework uses agile software life cycle methodology to implement guidelines towards the ethical upgrade of any existing AI system or the development of any new ethically aligned AI system. The guidelines enforce, among others, the minimisation of intentional harm and bias, diversity in data collection, design compliance, auditing of all activities in the framework and ease of code inspection. This framework will inform AI developers, users, conservationists, and policymakers on what to consider when integrating AI Ethics into AI-based systems for wildlife conservation.",AI Ethics; AI Ethics integration; AI in wildlife conservation; Artificial intelligence; Human–wildlife conflicts; Wildlife conservation concerns,,0951-5666,2021-09,2023-11-06 01:29:48,2023-11-06 01:29:48,245–257,,,QIMKGXJF,0.1714285714285714,0.4375,0.2222222222222222,0.1974425263391988
18,20,20,Utilizing User Stories To&nbsp;Bring AI Ethics Into&nbsp;Practice In&nbsp;Software Engineering,"Product-Focused Software Process Improvement: 23rd International Conference, PROFES 2022, Jyväskylä, Finland, November 21–23, 2022, Proceedings",,,10.1007/978-3-031-21388-5_41,"Kemell, Kai-Kristian; Vakkuri, Ville; Halme, Erika",2022.0,https://doi.org/10.1007/978-3-031-21388-5_41,conferencePaper,"AI ethics is a research area characterized by a prominent gap between research and practice. With most studies in the area being conceptual in nature or focused on technical ML (Machine Learning) solutions, the link between AI (Artificial Intelligence) ethics and SE (Software Engineering) practice remains thin. Establishing this link, we argue, is vital going forward. While conceptual discussion is required to define AI ethics, much progress has already been made in this regard. Similarly, though technical ML solutions are also required for practical implementation, ML systems are ultimately still software, and thus SE cannot be forgotten. In this paper, we propose one way of bringing AI ethics closer to conventional SE practice: utilizing user stories to implement AI ethics by means of Ethical User Stories (EUS). EUS can be used to formulate both functional and non-functional requirements, although an ethical framework is required produce them. By treating AI ethics as a part of the development process in this fashion, as opposed to a separate task, it can ideally become a part of SE for ML systems.",AI ethics; Artificial Intelligence; Ethical tool; Ethical user story; User story,978-3-031-21387-8,,2022,2023-11-06 01:29:48,2023-11-06 01:29:48,553–558,,Springer-Verlag,2VG4RNXX,0.135593220338983,0.8181818181818182,0.3333333333333333,0.192289315187082
20,22,22,A Literature Review on Digital Ethics from a Humanistic and Sustainable Perspective,Proceedings of the 14th International Conference on Theory and Practice of Electronic Governance,,,10.1145/3494193.3494295,"Teran, Luis; Pincay, Jhonny; Wallimann-Helmer, Ivo; Portmann, Edy",2022.0,https://doi.org/10.1145/3494193.3494295,conferencePaper,"The rapid technological transition requires the adoptive approach to the digital conduct of public and private institutions. Countries and companies strive to integrate a balanced understanding of digital ethics and sustainability concepts from various standpoints, which results in a dispersed and uncategorized knowledge base. This work presents a literature review on digital ethics published from 2010 to 2020 in three technical libraries and one library maintained by the community of philosophers. The investigation process integrates a thorough review of digital ethics concepts in the leading academic libraries using keywords representing various concept applications. This study's outcome is a quantitative and sectorial categorization of works on digital ethics, followed by a holistic review of concepts, maturity level, and conclusions on each category. This work aims to understand the trends from a technological and philosophical perspective towards designing a sustainable digital ethical framework applied in digital services that fulfill sufficiency thresholds of justice and do not foster overshooting of planetary boundaries. The first version of a holistic framework based on the literature review is presented at the end of this work. It will be extended in future work.",digital ethics; ethical challenge; humanistic; literature review; sustainability,978-1-4503-9011-8,,2022,2023-11-06 01:29:48,2023-11-06 01:29:48,57–64,ICEGOV '21,Association for Computing Machinery,WG3RQG8Q,0.1397849462365591,0.875,0.3333333333333333,0.1912146992792153
21,23,23,How Does Value Similarity Affect Human Reliance in AI-Assisted Ethical Decision Making?,"Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3600211.3604709,"Narayanan, Saumik; Yu, Guanghui; Ho, Chien-Ju; Yin, Ming",2023.0,https://doi.org/10.1145/3600211.3604709,conferencePaper,"This paper explores the impact of value similarity between humans and AI on human reliance in the context of AI-assisted ethical decision-making. Using kidney allocation as a case study, we conducted a randomized human-subject experiment where workers were presented with ethical dilemmas in various conditions, including no AI recommendations, recommendations from a similar AI, and recommendations from a dissimilar AI. We found that recommendations provided by a dissimilar AI had a higher overall effect on human decisions than recommendations from a similar AI. However, when humans and AI disagreed, participants were more likely to change their decisions when provided with recommendations from a similar AI. The effect was not due to humans’ perceptions of the AI being similar, but rather due to the AI displaying similar ethical values through its recommendations. We also conduct a preliminary analysis on the relationship between value similarity and trust, and potential shifts in ethical preferences at the population-level.",AI ethics; ethical preference; human reliance on AI,9798400702310,,2023,2023-11-06 01:29:49,2023-11-06 01:29:49,49–57,AIES '23,Association for Computing Machinery,BYSWACNN,0.1493506493506493,0.875,0.25,0.1882661343758282
22,24,24,Ethical Framework for Artificial Intelligence and Digital Technologies,Int. J. Inf. Manag.,62.0,C,10.1016/j.ijinfomgt.2021.102433,"Ashok, Mona; Madan, Rohit; Joha, Anton; Sivarajah, Uthayasankar",2022.0,https://doi.org/10.1016/j.ijinfomgt.2021.102433,journalArticle,"The use of Artificial Intelligence (AI) in Digital technologies (DT) is proliferating a profound socio-technical transformation. Governments and AI scholarship have endorsed key AI principles but lack direction at the implementation level. Through a systematic literature review of 59 papers, this paper contributes to the critical debate on the ethical use of AI in DTs beyond high-level AI principles. To our knowledge, this is the first paper that identifies 14 digital ethics implications for the use of AI in seven DT archetypes using a novel ontological framework (physical, cognitive, information, and governance). The paper presents key findings of the review and a conceptual model with twelve propositions highlighting the impact of digital ethics implications on societal impact, as moderated by DT archetypes and mediated by organisational impact. The implications of intelligibility, accountability, fairness, and autonomy (under the cognitive domain), and privacy (under the information domain) are the most widely discussed in our sample. Furthermore, ethical implications related to the governance domain are shown to be generally applicable for most DT archetypes. Implications under the physical domain are less prominent when it comes to AI diffusion with one exception (safety). The key findings and resulting conceptual model have academic and professional implications.",Artificial Intelligence (AI) ethics; Digital ethics; Digital technologies and archetypes; Ontological framework; PRISMA; Systematic literature review,,0268-4012,2022-02,2023-11-06 01:29:50,2023-11-06 01:29:50,,,,RGCVHYXK,0.1243781094527363,0.5625,0.625,0.1866909628874262
23,25,25,Getting into the Engine Room: A Blueprint to Investigate the Shadowy Steps of AI Ethics,AI Soc.,36.0,2,10.1007/s00146-020-01069-w,"Rochel, Johan; Evéquoz, Florian",2021.0,https://doi.org/10.1007/s00146-020-01069-w,journalArticle,"Enacting an AI system typically requires three iterative phases where AI engineers are in command: selection and preparation of the data, selection and configuration of algorithmic tools, and fine-tuning of the different parameters on the basis of intermediate results. Our main hypothesis is that these phases involve practices with ethical questions. This paper maps these ethical questions and proposes a way to address them in light of a neo-republican understanding of freedom, defined as absence of domination. We thereby identify different types of responsibility held by AI engineers and link them to concrete suggestions on how to improve professional practices. This paper contributes to the literature on AI and ethics by focusing on the work necessary to configure AI systems, thereby offering an input to better practices and an input for societal debates.",AI ethics; Applied ethics; Data ethics; Data science; Responsible innovation,,0951-5666,2021-06,2023-11-06 01:29:48,2023-11-06 01:29:48,609–622,,,GFZ5PDIF,0.1203007518796992,0.9,0.2,0.1844392959142041
24,26,26,Trustworthy AI for the People?,"Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3461702.3462470,"Figueras, Clàudia; Verhagen, Harko; Cerratto Pargman, Teresa",2021.0,https://doi.org/10.1145/3461702.3462470,conferencePaper,"While AI systems become more pervasive, their social impact is increasingly hard to measure. To help mitigate possible risks and guide practitioners into a more responsible design, diverse organizations have released AI ethics frameworks. However, it remains unclear how ethical issues are dealt with in the everyday practices of AI developers. To this end, we have carried an exploratory empirical study interviewing AI developers working for Swedish public organizations to understand how ethics are enacted in practice. Our analysis found that several AI ethics issues are not consistently tackled, and AI systems are not fully recognized as part of a broader sociotechnical system.",AI ethics in practice; AI in public organizations; citizen empowerment; responsible AI; responsible AI principles in practice; trustworthy AI,978-1-4503-8473-5,,2021,2023-11-06 01:29:49,2023-11-06 01:29:49,269–270,AIES '21,Association for Computing Machinery,4VB2H2EN,0.145631067961165,0.3684210526315789,0.2,0.1842344041757601
25,27,27,Design Science Research and Designing Ethical Guidelines for the SHAPES AI Developers,Procedia Comput. Sci.,192.0,C,10.1016/j.procs.2021.08.223,"Nevanperä, Minna; Rajamäki, Jyri; Helin, Jaakko",2021.0,https://doi.org/10.1016/j.procs.2021.08.223,journalArticle,"This article targets the design process of ethical guidelines for the SHAPES project (Smart and Healthy Aging through People Engaging in Supportive Systems) which is a H2020 Innovation Action project. The aim of the project is to build solutions that can make it easier for older individuals to live at home, such as, robots, wearables and sensor technologies that apply artificial intelligence (AI). The guiding method of the design process of ethical guidelines is Alan Hevner’s Design Science Research. Theoretical background consists of a form of literature overview, which contains the most relevant ethical theories and research on AI ethics, machine ethics and human rights. This article introduces the process of building the ethical guidelines for the SHAPES project and further discussion if providing guidelines is the sufficient tool to developers to take ethical action in development of the AI systems. The SHAPES guidelines include the following themes; accountability, transparency and explainability, diversity, inclusion and fairness, safety and security and societal wellbeing and humanity.",Design Science Reseach; Ethical Competence; Ethical Guidelines; SHAPES,,1877-0509,2021-01,2023-11-06 01:30:03,2023-11-06 01:30:03,2330–2339,,,9ZGXWGLX,0.1341463414634146,0.75,0.3333333333333333,0.1816468560255222
27,30,30,Designing Up with Value-Sensitive Design: Building a Field Guide for Ethical ML Development,"Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency",,,10.1145/3531146.3534626,"Boyd, Karen",2022.0,https://doi.org/10.1145/3531146.3534626,conferencePaper,"If “studying up,” or researching powerful actors in a social system, can offer insight into the workings and effects of power in social systems, this paper argues that “designing up” will give researchers and designers a tool to intervene. This paper offers a conception of “designing up,” applies the structure of Value Sensitive Design (VSD) to accomplish it, and submits an example of a tool designed to support ethical sensitivity, especially particularization and judgment. The designed artifact is a field guide for ethical mitigation strategies that uses tool profiles and filters to aid machine learning (ML) engineers as they build understanding of an ethical issue they have recognized and as they match the particulars of their problem to a technical ethical mitigation. This guide may broaden its users’ awareness of potential ethical issues, important features of ethical issues and their mitigations, and the breadth of available mitigations. Additionally, it may encourage ethical sensitivity in future ML projects. Feedback from ML engineers and technology ethics researchers rendered several usability improvements and ideas for future development. The tool can be found at: https://ml-ethics-tool.web.app/.",AI ethics; ethics; machine learning; datasets; development practices; ethical sensitivity,978-1-4503-9352-2,,2022,2023-11-06 01:30:01,2023-11-06 01:30:01,2069–2082,FAccT '22,Association for Computing Machinery,TH8CRF2C,0.1270718232044199,0.8,0.2307692307692307,0.1764500794887535
28,31,31,Ethical Awareness of UXers in the Loop: Ethical Issues in the Uxer-AI Collaboration Process from a UX Perspective,Proceedings of the 25th International Conference on Mobile Human-Computer Interaction,,,10.1145/3565066.3608691,"Yoon, Harin; Jun, Soojin",2023.0,https://doi.org/10.1145/3565066.3608691,conferencePaper,"Artificial Intelligence (AI) has emerged as a prominent collaborative tool across diverse domains, driving innovation in various tasks. However, this human–AI process brings forth a range of ethical considerations that require careful examination. This study investigates the ethical concerns that arise during the user experience designer (UXer)–AI co-creation process and the evolving role of UXers. Employing a mixed methods approach, combining observational task performance experiments and in-depth interviews, the study captures UXers' perceptions of ethical issues in the UXer-AI co-creation process. The findings shed light on three prominent ethical challenges in the UXer–AI co-creation process: reliability, bias, and unemployment. Consequently, this study emphasizes the crucial role of UXers, such as fact-checking, empathy-based decision making, and effective communication with AI, mitigating these ethical challenges. These findings enhance our understanding of UXers' responsibilities and shed light on the potential of leveraging AI as an effective collaborative tool for task completion.",AI Ethics; Generative AI; Co-Creation; Ethical UX; Uxer-AI Co-Creation Model,978-1-4503-9924-1,,2023,2023-11-06 01:30:01,2023-11-06 01:30:01,,MobileHCI '23 Companion,Association for Computing Machinery,72KLRSH2,0.1216216216216216,0.7,0.3333333333333333,0.1740387491738843
29,32,32,Mapping Research Strands of Ethics of Artificial Intelligence in Healthcare: A Bibliometric and Content Analysis,Comput. Biol. Med.,135.0,C,10.1016/j.compbiomed.2021.104660,"Saheb, Tahereh; Saheb, Tayebeh; Carpenter, David O.",2021.0,https://doi.org/10.1016/j.compbiomed.2021.104660,journalArticle,"The growth of artificial intelligence in promoting healthcare is rapidly progressing. Notwithstanding its promising nature, however, AI in healthcare embodies certain ethical challenges as well. This research aims to delineate the most influential elements of scientific research on AI ethics in healthcare by conducting bibliometric, social network analysis, and cluster-based content analysis of scientific articles. Not only did the bibliometric analysis identify the most influential authors, countries, institutions, sources, and documents, but it also recognized four ethical concerns associated with 12 medical issues. These ethical categories are composed of normative, meta-ethics, epistemological and medical practice. The content analysis complemented this list of ethical categories and distinguished seven more ethical categories: ethics of relationships, medico-legal concerns, ethics of robots, ethics of ambient intelligence, patients' rights, physicians’ rights, and ethics of predictive analytics. This analysis likewise identified 40 general research gaps in the literature and plausible future research strands. This analysis furthers conversations on the ethics of AI and associated emerging technologies such as nanotech and biotech in healthcare, hence, advances convergence research on the ethics of AI in healthcare. Practically, this research will provide a map for policymakers and AI engineers and scientists on what dimensions of AI-based medical interventions require stricter policies and guidelines and robust ethical design and development.",Ethics; Artificial intelligence; Content analysis; Healthcare; Bibliometric analysis; Network visualization; Robotics,,0010-4825,2021-08,2023-11-06 01:30:04,2023-11-06 01:30:04,,,,2BYKVZ92,0.1761904761904762,0.1818181818181818,0.1333333333333333,0.1738921640697445
30,33,33,Mental Contents in Designing AI Ethics,"Culture and Computing: 10th International Conference, C&amp;C 2022, Held as Part of the 24th HCI International Conference, HCII 2022, Virtual Event, June 26 – July 1, 2022, Proceedings",,,10.1007/978-3-031-05434-1_32,"Saariluoma, Pertti; Myllylä, Mari; Karvonen, Antero",2022.0,https://doi.org/10.1007/978-3-031-05434-1_32,conferencePaper,"In future intelligent digital society, the way people organize their life around technologies shall change because intelligent machines can follow ethical rules in their behavior. In the human mind, ethics exist as contents of mental representations. Therefore, it is important to investigate the information contents of mental representations or mental contents. One can also call this approach content-based cognitive research. The analysis of mental contents makes it possible to mimic human ethical information processing and construct human digital twins for designing ethical machine information processes. In this paper, we analyze the relevant AI aspects of Hume’s guillotine. Hume asked critically whether facts can be used to derive values. His answer was negative. However, modern information technology can collect huge masses of facts, but can these facts be used in improving how we should live? Content-based analysis of human ethical information processing opens possibilities to bypass the logical dilemma of Hume’s guillotine.",Ethical discourse; Hume’s guillotine; Mental contents; Weak and strong ethical AI,978-3-031-05433-4,,2022,2023-11-06 01:29:48,2023-11-06 01:29:48,477–487,,Springer-Verlag,ZWPT3FNA,0.1258278145695364,0.6363636363636364,0.5,0.173611085946733
31,34,34,From the Ground Truth up: Doing AI Ethics from Practice to Principles,AI Soc.,38.0,4,10.1007/s00146-021-01336-4,"Brusseau, James",2022.0,https://doi.org/10.1007/s00146-021-01336-4,journalArticle,"Recent AI ethics has focused on applying abstract principles downward to practice. This paper moves in the other direction. Ethical insights are generated from the lived experiences of AI-designers working on tangible human problems, and then cycled upward to influence theoretical debates surrounding these questions: (1) Should AI as trustworthy be sought through explainability, or accurate performance? (2) Should AI be considered trustworthy at all, or is reliability a preferable aim? (3) Should AI ethics be oriented toward establishing protections for users, or toward catalyzing innovation? Specific answers are less significant than the larger demonstration that AI ethics is currently unbalanced toward theoretical principles, and will benefit from increased exposure to grounded practices and dilemmas.",AI case studies; AI ethics; Healthcare AI; Philosophy and AI; Trustworthy AI,,0951-5666,2022-01,2023-11-06 01:29:48,2023-11-06 01:29:48,1651–1657,,,8GLT86ME,0.1217391304347826,0.5833333333333334,0.3333333333333333,0.1735443018845113
32,35,35,A Study on the Modeling of Major Factors for the Principles of AI Ethics,DG.O2021: The 22nd Annual International Conference on Digital Government Research,,,10.1145/3463677.3463733,"Lim, Ji Hun; Kwon, Hun Yeong",2021.0,https://doi.org/10.1145/3463677.3463733,conferencePaper,"The fourth industrial revolution, centered on artificial intelligence (AI), signals a significant transformation in human society. For this social transformation to ultimately be for humankind's prosperity and happiness, serious consideration of AI ethics is needed. As a result, many countries have begun to establish AI ethics principles, and the international community is pushing for standardization on AI ethics principles. This study aims to derive general factors of ethical principles that should be considered to establish and standardize AI ethics principles. To this end, we present a ""general AI ethics principles model,"" including 12 major factors, based on the recently published AI ethics principles in 15 countries. Furthermore, the major factors for AI ethics principles that we derived through this study ultimately confirmed that AI should be useful to all humans and is oriented toward the value of building a ""Trustworthy"" AI society. Based on these fundamental ideologies, we confirmed that each factor interconnects with each other. It is hoped that the AI ethics principles model that reflects this will be referred to national and international communities that have yet to develop Principles of AI Ethics. However, Factors for AI ethics principles should be constructed following the principles' intent and goal orientation, ensuring its feasibility, rather than merely duplicating the principles model.",,978-1-4503-8492-6,,2021,2023-11-06 01:29:49,2023-11-06 01:29:49,208–218,DG.O'21,Association for Computing Machinery,CP5RISCE,0.1706161137440758,0.0,0.2142857142857142,0.1727108580738546
33,36,36,The European Commission Report on Ethics of Connected and Automated Vehicles and the Future of Ethics of Transportation,Ethics and Inf. Technol.,23.0,4,10.1007/s10676-021-09609-8,"Santoni de Sio, Filippo",2021.0,https://doi.org/10.1007/s10676-021-09609-8,journalArticle,"The paper has two goals. The first is presenting the main results of the recent report Ethics of Connected and Automated Vehicles: recommendations on road safety, privacy, fairness, explainability and responsibility written by the Horizon 2020 European Commission Expert Group to advise on specific ethical issues raised by driverless mobility, of which the author of this paper has been member and rapporteur. The second is presenting some broader ethical and philosophical implications of these recommendations, and using these to contribute to the establishment of Ethics of Transportation as an independent&nbsp;branch of applied ethics. The recent debate on the ethics of Connected and Automated Vehicles (CAVs) presents a paradox and an opportunity. The paradox is the presence of a flourishing debate on the ethics of one very specific transportation technology without ethics of transportation being in itself a well-established academic discipline. The opportunity is that now that a spotlight has been switched on the ethical dimensions of CAVs it may be easier to establish a broader debate on ethics of transportation. While the 20 recommendations of the EU report are grouped in three macro-areas: road safety, data ethics, and responsibility, in this paper they will be grouped according to eight philosophical themes: Responsible Innovation, road justice, road safety, freedom, human control, privacy, data fairness, responsibility. These are proposed as the first topics for a new ethics of transportation.",Ethics of self-driving cars; Ethics of transportation; European Commission Report on ethics of CAVs; Responsible innovation in self-driving cars,,1388-1957,2021-12,2023-11-06 01:30:04,2023-11-06 01:30:04,713–726,,,BSYCZR64,0.1541850220264317,0.3157894736842105,0.2222222222222222,0.1717578331536133
34,37,37,Rebuilding 'ethics' to Govern AI: How to Re-Set the Boundaries for the Legal Sector?,Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law,,,10.1145/3594536.3595156,"Unver, Mehmet B.",2023.0,https://doi.org/10.1145/3594536.3595156,conferencePaper,"Artificial intelligence (AI) has been transforming the legal sector and profession given every day enhancing AI-driven legal tech tools. Considering the far-reaching ethical implications of such tools and the disparate functionalities of 'AI ethics' and 'legal ethics', this paper puts into question the interplay between these ethical domains and their underlying rules. After fleshing out the governance of ethics under each domain, e.g. respectively professional conduct rules and self-regulatory principles, and signposting the unresolved ethical challenges of status quo, e.g. particularly concerning cross-domain issues, the paper discusses how they need to interact, based on the three policy options: 'revision of the conduct rules', 'individual (company level) collaboration' and 'higher-level collaboration'. It is concluded that 'higher-level collaboration' between the stakeholders is found to be the most sustainable and long-term option given the need to mitigate the ethical challenges concerning the legal sector from a holistic point of view.",AI ethics; fairness; accountability; transparency; Legal ethics,9798400701979,,2023,2023-11-06 01:29:59,2023-11-06 01:29:59,306–315,ICAIL '23,Association for Computing Machinery,R8UG3WLT,0.1360544217687075,0.7142857142857143,0.2142857142857142,0.1717094798118252
35,38,38,Making Art with and about Artificial Intelligence: Three Approaches to Teaching AI and AI Ethics to Middle and High School Students,Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 2,,,10.1145/3478432.3499157,"Walsh, Benjamin; Ali, Safinah; Castro, Francisco; Desportes, Kayla; DiPaola, Daniella; Lee, Irene; Payne, William; Sieke, Scott; Zhang, Helen",2022.0,https://doi.org/10.1145/3478432.3499157,conferencePaper,"In this hands-on workshop participants will experience the curricula from three NSF funded projects, which engage youth in creating art with and about AI technologies while exploring related ethical concerns.danceON is a web-based creative coding environment that engages learners in creating multimedia dance performances. Besides writing reactive code that generates animations to augment dance performances, students also use the system to explore the boundaries and biases of AI.DAILy is a curriculum focused on developing AI literacy among middle school students through the integration of technical concepts and processes, ethical and societal implications, and career futures in AI. Participants will be focusing on the AI + art modules of DAILy.Imagine AI develops project-based curricula to support youth in exploring critical ethical issues related to AI. Students read short stories featuring youth at the center of AI ethical dilemmas, build and manipulate AI systems, and create digital media to express ethical stances.Participants will leave the workshop with multiple AI teaching strategies that blend technical learning with social purpose and creative expression.",ai ethics education; art; artificial intelligence education,978-1-4503-9071-2,,2022,2023-11-06 01:29:50,2023-11-06 01:29:50,1203,SIGCSE 2022,Association for Computing Machinery,EZQ5A6TG,0.1538461538461538,0.4285714285714285,0.1904761904761904,0.1691687840484339
36,39,39,AI Ethics and the Banality of Evil,Ethics and Inf. Technol.,23.0,3,10.1007/s10676-021-09587-x,"Tajalli, Payman",2021.0,https://doi.org/10.1007/s10676-021-09587-x,journalArticle,"In this paper, I draw on Hannah Arendt’s notion of ‘banality of evil’ to argue that as long as AI systems are designed to follow codes of ethics or particular normative ethical theories chosen by us and programmed in them, they are Eichmanns destined to commit evil. Since intelligence alone is not sufficient for ethical decision making, rather than strive to program AI to determine the right ethical decision based on some ethical theory or criteria, AI should be concerned with avoiding making the wrong decisions, and this requires hardwiring the thinking activity as a prerequisite for decision making.",Artificial Intelligence; Artificial Thinking; Banality of Evil,,1388-1957,2021-09,2023-11-06 01:29:48,2023-11-06 01:29:48,447–454,,,5CDJRHE9,0.1717171717171717,0.0,0.4285714285714285,0.1689992457037911
37,40,40,Seeing Like a Toolkit: How Toolkits Envision the Work of AI Ethics,Proc. ACM Hum.-Comput. Interact.,7.0,CSCW1,10.1145/3579621,"Wong, Richmond Y.; Madaio, Michael A.; Merrill, Nick",2023.0,https://doi.org/10.1145/3579621,journalArticle,"Numerous toolkits have been developed to support ethical AI development. However, toolkits, like all tools, encode assumptions in their design about what work should be done and how. In this paper, we conduct a qualitative analysis of 27 AI ethics toolkits to critically examine how the work of ethics is imagined and how it is supported by these toolkits. Specifically, we examine the discourses toolkits rely on when talking about ethical issues, who they imagine should do the work of ethics, and how they envision the work practices involved in addressing ethics. Among the toolkits, we identify a mismatch between the imagined work of ethics and the support the toolkits provide for doing that work. In particular, we identify a lack of guidance around how to navigate labor, organizational, and institutional power dynamics as they relate to performing ethical work. We use these omissions to chart future work for researchers and designers of AI ethics toolkits.",ethics; fairness; labor; toolkits; work,,,2023-04,2023-11-06 01:29:49,2023-11-06 01:29:49,,,,57LMLERK,0.1538461538461538,0.4,0.25,0.1686935969058874
38,41,41,What Does It Mean to Embed Ethics in Data Science? An Integrative Approach Based on Microethics and Virtues,AI Soc.,36.0,3,10.1007/s00146-020-01112-w,"Bezuidenhout, Louise; Ratti, Emanuele",2021.0,https://doi.org/10.1007/s00146-020-01112-w,journalArticle,"In the past few years, scholars have been questioning whether the current approach in data ethics based on the higher level case studies and general principles is effective. In particular, some have been complaining that such an approach to ethics is difficult to be applied and to be taught in the context of data science. In response to these concerns, there have been discussions about how ethics should be “embedded” in the practice of data science, in the sense of showing how ethical issues emerge in small technical choices made by data scientists in their day-to-day activities, and how such an approach can be used to teach data ethics. However, a precise description of how such proposals have to be theoretically conceived and could be operationalized has been lacking. In this article, we propose a full-fledged characterization of ‘embedding’ ethics, and how this can be applied especially to the problem of teaching data science ethics. Using the emerging model of ‘microethics’, we propose a way of teaching daily responsibility in digital activities that is connected to (and draws from) the higher level ethical challenges discussed in digital/data ethics. We ground this microethical approach into a virtue theory framework, by stressing that the goal of a microethics is to foster the cultivation of moral virtues. After delineating this approach of embedding ethics in theoretical detail, this article discusses a concrete example of how such a ‘micro-virtue ethics’ approach could be practically taught to data science students.",Embedded ethics; Data science; Virtue ethics; Microethics; Teaching ethics,,0951-5666,2021-09,2023-11-06 01:30:03,2023-11-06 01:30:03,939–953,,,B9TXHEP8,0.1387755102040816,0.7777777777777778,0.1666666666666666,0.167833615141625
39,42,42,A Sector-Based Approach to AI Ethics: Understanding Ethical Issues of AI-Related Incidents within Their Sectoral Context,"Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3600211.3604680,"Burema, Dafna; Debowski-Weimann, Nicole; von Janowski, Alexander; Grabowski, Jil; Maftei, Mihai; Jacobs, Mattis; van der Smagt, Patrick; Benbouzid, Djalel",2023.0,https://doi.org/10.1145/3600211.3604680,conferencePaper,"Acknowledging that society is made up of different sectors with their own rules and structures, this paper studies the relevance of a sector-specific perspective to AI ethics. Incidents with AI are studied in relation to five sectors (police, healthcare, education and academia, politics, automotive) using the AIAAIC repository. A total of 125 incidents are sampled and analyzed by conducting a qualitative content analysis on media reports. The results show that certain ethical principles are found breached across sectors: accuracy/reliability, bias/discrimination, transparency, surveillance/privacy, security. However, results also show that 1) some ethical issues (misinformation, safety, premise/intent) are sector specific, 2) the consequences and meaning of the same ethical issue is able to vary across sectors and 3) pre-existing sector-specific issues are reproduced with these ethical breaches. The paper concludes that general ethical principles are relevant to discuss across sectors, yet, a sector-based approach to AI ethics gives in-depth information on sector-specific structural issues.",,9798400702310,,2023,2023-11-06 01:29:48,2023-11-06 01:29:48,705–714,AIES '23,Association for Computing Machinery,4REIZHKM,0.1447368421052631,0.0,0.375,0.1672564663492472
40,43,43,Beyond Fairness and Explanation: Foundations of Trustworthiness of Artificial Agents,"Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3514094.3539570,"Malle, Bertram F.",2022.0,https://doi.org/10.1145/3514094.3539570,conferencePaper,"The topics of fairness and explainability have dominated recent discussions of ethical AI. However, these are only two criteria that would make artificial agents anywhere close to ethical. I frame the question of ethical AI, and especially ethical social robots, as the question of what would make them worthy of human trust and actually eliciting human trust. Relying on a recent investigation of the multi-dimensionality of human trust, I lay out five criteria of trustworthiness-being competent, reliable, transparent, benevolent, and having ethical integrity. I will argue that an essential ingredient of such trustworthiness is norm competence-the ability to represent, comply with, and learn relevant social-moral norms (including fairness as one among many). I discuss the challenges to implementing norm competence and the critical role that justification, not just explanation, will play in providing evidence for such competence.",fairness; explainability; norms; ethical ai; trust; xai; robotethics; trustworthiness,978-1-4503-9247-1,,2022,2023-11-06 01:29:55,2023-11-06 01:29:55,4,AIES '22,Association for Computing Machinery,2I4CL7D7,0.145985401459854,0.5555555555555556,0.0,0.1663380091994811
41,44,44,Ethical Data Curation for AI: An Approach Based on Feminist Epistemology and Critical Theories of Race,"Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3461702.3462598,"Leavy, Susan; Siapera, Eugenia; O'Sullivan, Barry",2021.0,https://doi.org/10.1145/3461702.3462598,conferencePaper,"The potential for bias embedded in data to lead to the perpetuation of social injustice though Artificial Intelligence (AI) necessitates an urgent reform of data curation practices for AI systems, especially those based on machine learning. Without appropriate ethical and regulatory frameworks there is a risk that decades of advances in human rights and civil liberties may be undermined. This paper proposes an approach to data curation for AI, grounded in feminist epistemology and informed by critical theories of race and feminist principles. The objective of this approach is to support critical evaluation of the social dynamics of power embedded in data for AI systems. We propose a set of fundamental guiding principles for ethical data curation that address the social construction of knowledge, call for inclusion of subjugated and new forms of knowledge, support critical evaluation of theoretical concepts within data and recognise the reflexive nature of knowledge. In developing this ethical framework for data curation, we aim to contribute to a virtue ethics for AI and ensure protection of fundamental and human rights.",critical theories of race; data curation; ethical ai; feminist theory,978-1-4503-8473-5,,2021,2023-11-06 01:29:53,2023-11-06 01:29:53,695–703,AIES '21,Association for Computing Machinery,4G3QRRXZ,0.1314285714285714,0.5,0.3125,0.1649661682854959
42,45,45,Walking the Walk of AI Ethics: Organizational Challenges and the Individualization of Risk among Ethics Entrepreneurs,"Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",,,10.1145/3593013.3593990,"Ali, Sanna J.; Christin, Angèle; Smart, Andrew; Katila, Riitta",2023.0,https://doi.org/10.1145/3593013.3593990,conferencePaper,"Amidst decline in public trust in technology, computing ethics have taken center stage, and critics have raised questions about corporate “ethics washing.” Yet few studies examine the actual implementation of AI ethics values in technology companies. Based on a qualitative analysis of technology workers tasked with integrating AI ethics into product development, we find that workers experience an environment where policies, practices, and outcomes are decoupled. We analyze AI ethics workers as ethics entrepreneurs who work to institutionalize new ethics-related practices within organizations. We show that ethics entrepreneurs face three major barriers to their work. First, they struggle to have ethics prioritized in an environment centered around software product launches. Second, ethics are difficult to quantify in a context where company goals are incentivized by metrics. Third, the frequent reorganization of teams makes it difficult to access knowledge and maintain relationships central to their work. Consequently, individuals take on great personal risk when raising ethics issues, especially when they come from marginalized backgrounds. These findings shed light on complex dynamics of institutional change at technology companies.",AI ethics; decoupling; institutional change; neo-institutionalism; organizations; responsible AI; Science and Technology Studies,9798400701924,,2023,2023-11-06 01:29:48,2023-11-06 01:29:48,217–226,FAccT '23,Association for Computing Machinery,54WS3WZI,0.1363636363636363,0.3076923076923077,0.3125,0.1647601814073776
48,51,51,Automated Kantian Ethics,"Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3514094.3539527,"Singh, Lavanya",2022.0,https://doi.org/10.1145/3514094.3539527,conferencePaper,"As we grant artificial intelligence increasing power and independence in contexts like healthcare, policing, and driving, AI faces moral dilemmas but lacks the tools to solve them. The dangers of unethical AI motivate automated ethics-i.e., the development of machines that can perform ethical reasoning. Though philosophically sophisticated ethical theories enable nuanced judgements, prior work in automated ethics rarely engages with philosophical literature. I contribute an implementation of automated Kantian ethics that is faithful to the Kantian philosophical tradition. My system can morally judge actions and is an early step towards philosophically mature ethical AI agents. I hope to develop an ""input parser"" that can parse natural language sentences into logical formulas that my system can evaluate.",Kant; automated ethics; Dyadic Deontic Logic; Isabelle/HOL,978-1-4503-9247-1,,2022,2023-11-06 01:29:54,2023-11-06 01:29:54,915,AIES '22,Association for Computing Machinery,UMPN42CE,0.1379310344827586,0.2857142857142857,0.6666666666666666,0.1616599225897255
50,53,53,Organisational Responses to the Ethical Issues of Artificial Intelligence,AI Soc.,37.0,1,10.1007/s00146-021-01148-6,"Stahl, Bernd Carsten; Antoniou, Josephina; Ryan, Mark; Macnish, Kevin; Jiya, Tilimbe",2022.0,https://doi.org/10.1007/s00146-021-01148-6,journalArticle,"The ethics of artificial intelligence (AI) is a widely discussed topic. There are numerous initiatives that aim to develop the principles and guidance to ensure that the development, deployment and use of AI are ethically acceptable. What is generally unclear is how organisations that make use of AI understand and address these ethical issues in practice. While there is an abundance of conceptual work on AI ethics, empirical insights are rare and often anecdotal. This paper fills the gap in our current understanding of how organisations deal with AI ethics by presenting empirical findings collected using a set of ten case studies and providing an account of the cross-case analysis. The paper reviews the discussion of ethical issues of AI as well as mitigation strategies that have been proposed in the literature. Using this background, the cross-case analysis categorises the organisational responses that were observed in practice. The discussion shows that organisations are highly aware of the AI ethics debate and keen to engage with ethical issues proactively. However, they make use of only a relatively small subsection of the mitigation strategies proposed in the literature. These insights are of importance to organisations deploying or using AI, to the academic AI ethics debate, but maybe most valuable to policymakers involved in the current debate about suitable policy developments to address the ethical issues raised by AI.",Ethics; Artificial intelligence; AI policy; Case study; Organisational response,,0951-5666,2022-03,2023-11-06 01:30:00,2023-11-06 01:30:00,23–37,,,A8WHBU5L,0.1415929203539823,0.3333333333333333,0.3333333333333333,0.1597741697444135
51,54,54,Artificial Intelligence ELSI Score for Science and Technology: A Comparison between Japan and the US,AI Soc.,38.0,4,10.1007/s00146-021-01323-9,"Hartwig, Tilman; Ikkatai, Yuko; Takanashi, Naohiro; Yokoyama, Hiromi M.",2022.0,https://doi.org/10.1007/s00146-021-01323-9,journalArticle,"Artificial intelligence (AI) has become indispensable in our lives. The development of a quantitative scale for AI ethics is necessary for a better understanding of public attitudes toward AI research ethics and to advance the discussion on using AI within society. For this study, we developed an AI ethics scale based on AI-specific scenarios. We investigated public attitudes toward AI ethics in Japan and the US using online questionnaires. We designed a test set using four dilemma scenarios and questionnaire items based on a theoretical framework for ethics, legal, and social issues (ELSI). We found that country and age are the most informative sociodemographic categories for predicting attitudes for AI ethics. Our proposed scale, which consists of 13 questions, can be reduced to only three, covering ethics, tradition, and policies. This new AI ethics scale will help to quantify how AI research is accepted in society and which area of ELSI people are most concerned with.",Ethics; Artificial Intelligence; Dilemma; ELSI,,0951-5666,2022-01,2023-11-06 01:29:59,2023-11-06 01:29:59,1609–1626,,,D4YXJKJ7,0.1602564102564102,0.4,0.0,0.1558417142339404
53,56,56,Epistemic Reasoning for Machine Ethics with Situation Calculus,"Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3461702.3462586,"Pagnucco, Maurice; Rajaratnam, David; Limarga, Raynaldio; Nayak, Abhaya; Song, Yang",2021.0,https://doi.org/10.1145/3461702.3462586,conferencePaper,"With the rapid development of autonomous machines such as selfdriving vehicles and social robots, there is increasing realisation that machine ethics is important for widespread acceptance of autonomous machines. Our objective is to encode ethical reasoning into autonomous machines following well-defined ethical principles and behavioural norms. We provide an approach to reasoning about actions that incorporates ethical considerations. It builds on Scherl and Levesque's [29, 30] approach to knowledge in the situation calculus. We show how reasoning about knowledge in a dynamic setting can be used to guide ethical and moral choices, aligned with consequentialist and deontological approaches to ethics. We apply our approach to autonomous driving and social robot scenarios, and provide an implementation framework.",machine ethics; epistemic logic; knowledge representation; situation calculus,978-1-4503-8473-5,,2021,2023-11-06 01:29:57,2023-11-06 01:29:57,814–821,AIES '21,Association for Computing Machinery,AAT628QT,0.1379310344827586,0.25,0.25,0.1541408016075209
54,57,57,Broadening AI Ethics Narratives: An Indic Art View,"Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",,,10.1145/3593013.3593971,"Divakaran, Ajay; Sridhar, Aparna; Srinivasan, Ramya",2023.0,https://doi.org/10.1145/3593013.3593971,conferencePaper,"Incorporating interdisciplinary perspectives is seen as an essential step towards enhancing artificial intelligence (AI) ethics. In this regard, the field of arts is perceived to play a key role in elucidating diverse historical and cultural narratives, serving as a bridge across research communities. Most of the works that examine the interplay between the field of arts and AI ethics concern digital artworks, largely exploring the potential of computational tools in being able to surface biases in AI systems. In this paper, we investigate a complementary direction–that of uncovering the unique socio-cultural perspectives embedded in human-made art, which in turn, can be valuable in expanding the horizon of AI ethics. Through semi-structured interviews across sixteen artists, art scholars, and researchers of diverse Indian art forms like music, sculpture, painting, floor drawings, dance, etc., we explore how non-Western ethical abstractions, methods of learning, and participatory practices observed in Indian arts, one of the most ancient yet perpetual and influential art traditions, can shed light on aspects related to ethical AI systems. Through a case study concerning the Indian dance system (i.e. the ‘Natyashastra’), we analyze potential pathways towards enhancing ethics in AI systems. Insights from our study outline the need for (1) incorporating empathy in ethical AI algorithms, (2) integrating multimodal data formats for ethical AI system design and development, (3) viewing AI ethics as a dynamic, diverse, cumulative, and shared process rather than as a static, self-contained framework to facilitate adaptability without annihilation of values (4) consistent life-long learning to enhance AI accountability",AI ethics; Indian arts,9798400701924,,2023,2023-11-06 01:29:48,2023-11-06 01:29:48,2–11,FAccT '23,Association for Computing Machinery,4SQQGBXJ,0.1388888888888889,0.75,0.375,0.1528314620528867
55,58,58,Centring Dignity in Algorithm Development: Testing a Dignity Lens,Proceedings of the 34th Australian Conference on Human-Computer Interaction,,,10.1145/3572921.3572938,"Ruster, Lorenn P.; Oliva-Altamirano, Paola; Daniell, Katherine A.",2023.0,https://doi.org/10.1145/3572921.3572938,conferencePaper,"Against a backdrop of algorithms that disempower, dehumanise, disenfranchise and discriminate, there are increasing calls to centre the human in AI development processes and to humanise AI development in practice; centring dignity in AI development could provide a way forward. Despite the inclusion of dignity in many Artificial Intelligence (AI) ethics frameworks, like many other AI ethics principles, there is little operational understanding of what dignity can look like in practice when it comes to the development of algorithms. Drawing on cybernetics and a model of dignity developed in the field of international conflict resolution, this paper presents our work-in-progress tool - the Dignity Lens - for considering dignity throughout the AI development lifecycle, and practitioner reflections from using the tool. This work is an initial step towards articulating what dignity-centred AI development could look like in practice, assisting practitioners designing and developing algorithms to actively consider dignity.",AI Ethics; Cybernetics; Dignity; Interaction Design,9798400700248,,2023,2023-11-06 01:29:55,2023-11-06 01:29:55,1–8,OzCHI '22,Association for Computing Machinery,6GZV636E,0.1216216216216216,0.6666666666666666,0.2222222222222222,0.1515835206934683
